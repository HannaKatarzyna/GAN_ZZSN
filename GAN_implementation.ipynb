{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'D:\\studia mgr EIM\\ZZSN\\thecarconnectionpicturedataset'\n",
    "listOfFiles = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opcja 1 - rozdzielenie na typy, w car_types przechowywane nazwy plikow\n",
    "\n",
    "car_types= ['Van','Pickup','Station Wagon','4dr','3dr','2dr','SUV','Convertible']\n",
    "# reszta to 'nan'\n",
    "car_dictionary = dict.fromkeys(car_types)\n",
    "for type_of_car in car_types:\n",
    "    str_match = [s for s in listOfFiles if type_of_car in s]\n",
    "    car_dictionary[type_of_car] = str_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inicjalizacja parametrow\n",
    "# rozmiar zdjec 320x213 pikseli, niektore na x240 piskeli, \n",
    "# TODO: trzeba funkcje, by byÅ‚y wszystkie w tym samym rozmiarze -> resize()\n",
    "\n",
    "# image = Image.open('demo_image.jpg')\n",
    "# new_image = image.resize((400, 400))\n",
    "# new_image.save('image_400.jpg')  \n",
    "\n",
    "# z czego korzystam? https://jovian.ai/tvscitechtalk/car-gan\n",
    "# https://github.com/ozanciga/gans-with-pytorch/blob/master/cgan/cgan.py\n",
    "# https://github.com/eriklindernoren/PyTorch-GAN/blob/36d3c77e5ff20ebe0aeefd322326a134a279b93e/implementations/cgan/cgan.py#L189\n",
    "\n",
    "\n",
    "# stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "# train_ds = ImageFolder(DATA_DIR, transform=T.Compose([\n",
    "#     T.Resize(image_size),\n",
    "#     T.CenterCrop(image_size),\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize(*stats)])) # normalizacja, zeby dyskryminator mial latwiej-?\n",
    "\n",
    "# train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## klasa generatora\n",
    "# nn.Module - base class for all neural network modules\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## klasa dyskryminatora\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(Discriminator, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropia krzyzowa \n",
    "# TODO: ustalenie parametrow\n",
    "\n",
    "# torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=- 100, \n",
    "#     reduce=None, reduction='mean', label_smoothing=0.0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
